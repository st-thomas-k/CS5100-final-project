{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-19T23:05:23.994984Z",
     "start_time": "2024-04-19T23:05:23.988612Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pandas as pd\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load Model\n",
    "\n",
    "model_path = r'C:\\Users\\kyles\\Desktop\\CS5100\\Final_Project\\pose_landmarker_heavy.task'\n",
    "min_pose_detection_confidence = 0.5\n",
    "min_pose_presence_confidence = 0.5\n",
    "min_tracking_confidence = 0.5\n",
    "num_poses = 1\n",
    "last_timestamp_ms = 0\n",
    "labels = [\n",
    "    'Right Knee',\n",
    "    'Left Knee',\n",
    "    'Right Ankle',\n",
    "    'Left Ankle',\n",
    "    'Right Heel',\n",
    "    'Left Heel',\n",
    "    'Right Foot Index',\n",
    "    'Left Foot Index'\n",
    "]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T23:05:24.548239Z",
     "start_time": "2024-04-19T23:05:24.542338Z"
    }
   },
   "id": "53c91055c1d35276",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# input model parameters \n",
    "base_options = python.BaseOptions(model_asset_path=model_path)\n",
    "options = vision.PoseLandmarkerOptions(base_options=base_options,\n",
    "                                       running_mode=vision.RunningMode.VIDEO,\n",
    "                                       num_poses=num_poses,\n",
    "                                       min_pose_detection_confidence=min_pose_detection_confidence,\n",
    "                                       min_pose_presence_confidence=min_pose_presence_confidence,\n",
    "                                       min_tracking_confidence=min_tracking_confidence,\n",
    "                                       output_segmentation_masks=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T23:05:25.034645Z",
     "start_time": "2024-04-19T23:05:25.026734Z"
    }
   },
   "id": "1061dfd9144fc73b",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Functions to draw pose data\n",
    "\n",
    "def draw_skeleton(detection_result):\n",
    "    pose_landmarks_list = detection_result.pose_landmarks\n",
    "    blank = np.zeros((500, 800, 3), np.uint8)\n",
    "\n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(\n",
    "                x=landmark.x,\n",
    "                y=landmark.y,\n",
    "                z=landmark.z) for landmark in pose_landmarks\n",
    "        ])\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            blank,\n",
    "            pose_landmarks_proto,\n",
    "            mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            mp.solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "    return blank\n",
    "\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "    pose_landmarks_list = detection_result.pose_landmarks\n",
    "    annotated_copy = np.copy(rgb_image)\n",
    "\n",
    "    # Loop through the detected poses to visualize.\n",
    "    for idx in range(len(pose_landmarks_list)):\n",
    "        pose_landmarks = pose_landmarks_list[idx]\n",
    "\n",
    "        pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        pose_landmarks_proto.landmark.extend([\n",
    "            landmark_pb2.NormalizedLandmark(\n",
    "                x=landmark.x,\n",
    "                y=landmark.y,\n",
    "                z=landmark.z) for landmark in pose_landmarks\n",
    "        ])\n",
    "        mp.solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_copy,\n",
    "            pose_landmarks_proto,\n",
    "            mp.solutions.pose.POSE_CONNECTIONS,\n",
    "            mp.solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "    return annotated_copy"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T23:05:25.336287Z",
     "start_time": "2024-04-19T23:05:25.326313Z"
    }
   },
   "id": "81307f1936c134d4",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Functions for identifying good poses, extracting and reorganizing their data, and converting to DataFrame\n",
    "\n",
    "def test_image_range(data, x, y, save):\n",
    "    test_range = data[x:y]\n",
    "    path = r'C:\\Users\\kyles\\Desktop\\CS5100\\Final_Project\\skeleton_data'\n",
    "    for i in range(len(test_range)):\n",
    "        # out_file = shortened + '_' + str(i) + '.jpg'\n",
    "        test_output = draw_skeleton(test_range[i])\n",
    "        if save:\n",
    "            #cv2.imwrite(os.path.join(path, out_file), test_output)\n",
    "            continue\n",
    "        while True:\n",
    "            cv2.imshow('result', test_output)\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def get_lower_half_data(pose_data, x, y):\n",
    "    lower_half_data = []\n",
    "    trimmed_data = pose_data[x:y]\n",
    "\n",
    "    for i in range(len(trimmed_data)):\n",
    "        for each in trimmed_data[i].pose_landmarks:\n",
    "            lower_half_data.append(each[23::])\n",
    "    return lower_half_data\n",
    "\n",
    "\n",
    "def create_output(data_labels, data):\n",
    "    output = []\n",
    "    line = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data_labels)):\n",
    "            data_point = [data_labels[j], data[i][j]]\n",
    "            line.append(data_point)\n",
    "        output.append(line)\n",
    "        line = []\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def create_df(dataframe, columns):\n",
    "    pattern = re.compile(r\"\\['(.*?)', \\(x=(.*?), y=(.*?), z=(.*?), visibility=(.*?), presence=(.*?)\\)\\]\")\n",
    "    output_df = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for row in dataframe['Pose Data']:\n",
    "        data = []\n",
    "        row = str(row)\n",
    "        new_row = row.replace('NormalizedLandmark', '')\n",
    "        new_row = new_row[1:-1]\n",
    "        matches = pattern.findall(new_row)\n",
    "\n",
    "        for match in matches:\n",
    "            body_part = match[0]\n",
    "            measurements = tuple(map(float, match[1:]))\n",
    "            data.append((body_part, measurements))\n",
    "\n",
    "        data_df = pd.DataFrame([dict(data)])\n",
    "        output_df = pd.concat([output_df, data_df])\n",
    "    return output_df\n",
    "\n",
    "def get_pose_output(video_draw_data, start_frame, end_frame):\n",
    "    # Get 5 poses around kick. Start with pose directly before impact\n",
    "    \n",
    "    test_image_range(video_draw_data, start_frame, end_frame, False)\n",
    "    \n",
    "    # Extract data\n",
    "    lower_output = get_lower_half_data(video_draw_data, start_frame, end_frame)\n",
    "    final_output = create_output(labels, lower_output)\n",
    "    \n",
    "    return final_output\n",
    "\n",
    "def write_arr_to_csv(data_with_times, save_path):\n",
    "    cols = ['Right Knee', 'Left Knee', 'Right Ankle', 'Left Ankle', 'Right Heel', 'Left Heel', 'Right Foot Index', 'Left Foot Index']\n",
    "    \n",
    "    if os.path.isfile(formatted_data_path):\n",
    "        existing_df = pd.read_csv(save_path)\n",
    "        next_index = existing_df.tail(1)['Pose ID'].item() + 1\n",
    "        header = False\n",
    "    else:\n",
    "        next_index = 0\n",
    "        header = True\n",
    "    \n",
    "    df_output = pd.DataFrame(data_with_times, columns=['Time', 'Pose Data'])\n",
    "    df_output.dropna()\n",
    "    df_output = df_output.reset_index(drop=True)\n",
    "    \n",
    "\n",
    "    reformatted_df = create_df(df_output, cols)\n",
    "    reformatted_df.reset_index(drop=True, inplace=True)\n",
    "    reformatted_df['Pose ID'] = next_index\n",
    "\n",
    "    # Uncomment below when saving data\n",
    "    reformatted_df.to_csv(save_path, mode='a', header=header, index=False)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T23:05:26.003354Z",
     "start_time": "2024-04-19T23:05:25.986926Z"
    }
   },
   "id": "a2c66a3953dcdbfc",
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Check for good pose estimation and capture data\n",
    "\n",
    "def get_pose_data(file_path, flip):\n",
    "    pose_data = []\n",
    "    mp_data = []\n",
    "    pose_draw_data = []\n",
    "    time_stamps = []\n",
    "    \n",
    "    \n",
    "    shortened = file_path[-9:-4]\n",
    "    \n",
    "    with vision.PoseLandmarker.create_from_options(options) as landmarker:\n",
    "        cap = cv2.VideoCapture(file_path)\n",
    "        \n",
    "        while cap.isOpened():\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "    \n",
    "                break\n",
    "    \n",
    "            # When penalty is taken with left foot, uncomment below\n",
    "            if flip:\n",
    "                image = cv2.flip(image, 1)\n",
    "            \n",
    "            # Convert cv2 image to mediapipe image object\n",
    "            mp_image = mp.Image(\n",
    "                image_format=mp.ImageFormat.SRGB,\n",
    "                data=cv2.cvtColor(image[400:1000, 500:1200], cv2.COLOR_BGR2RGB))\n",
    "            timestamp_ms = int(cv2.getTickCount() / cv2.getTickFrequency() * 1000)\n",
    "            result = landmarker.detect_for_video(mp_image, timestamp_ms)\n",
    "            print(result.pose_world_landmarks)\n",
    "            pose_data.append(result.pose_world_landmarks)\n",
    "            annotated_image = draw_landmarks_on_image(mp_image.numpy_view(), result)\n",
    "    \n",
    "            if result.pose_world_landmarks:\n",
    "                if result.pose_world_landmarks[0][0].z > -.3 or result.pose_world_landmarks[0][1].z > -.3:\n",
    "                    # get frame_ms -- append to list\n",
    "                    frame_ms = cap.get(cv2.CAP_PROP_POS_MSEC)\n",
    "                    time_stamps.append(frame_ms / 1000)\n",
    "                    # draw frames\n",
    "                    pose_draw_data.append(result)\n",
    "                    mp_data.append(mp_image)\n",
    "    \n",
    "            cv2.imshow(\"MediaPipe Pose Landmark\", cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        cv2.destroyAllWindows()\n",
    "        cap.release()\n",
    "        return pose_draw_data, time_stamps"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T23:05:29.207090Z",
     "start_time": "2024-04-19T23:05:29.196401Z"
    }
   },
   "id": "aadc0d75b4fb2fc9",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: ''",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[16], line 14\u001B[0m\n\u001B[0;32m     11\u001B[0m     video_data, time_stamps \u001B[38;5;241m=\u001B[39m get_pose_data(new_path, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m go_ahead \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mn\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m---> 14\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEnter start frame int: \u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m     15\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28minput\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEnter end frame int: \u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m     16\u001B[0m     selected_data \u001B[38;5;241m=\u001B[39m get_pose_output(video_data, x, y)\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: ''"
     ]
    }
   ],
   "source": [
    "new_path = r'C:\\Users\\kyles\\Desktop\\CS5100\\Final_Project\\Test_Data\\fifa_data\\fifa16.mp4'\n",
    "\n",
    "go_ahead = 'n'\n",
    "\n",
    "\n",
    "flip_status = input('Flip image? y or n')\n",
    "\n",
    "if flip_status == 'y':\n",
    "    video_data, time_stamps = get_pose_data(new_path, True)\n",
    "else:\n",
    "    video_data, time_stamps = get_pose_data(new_path, False)\n",
    "\n",
    "while go_ahead == 'n':\n",
    "    x = int(input('Enter start frame int: '))\n",
    "    y = int(input('Enter end frame int: '))\n",
    "    selected_data = get_pose_output(video_data, x, y)\n",
    "\n",
    "    go_ahead = input('Proceed? y or n')\n",
    "    if go_ahead == 'y':\n",
    "        selected_times = time_stamps[x:y]\n",
    "        output_with_times = list(zip(selected_times, selected_data))\n",
    "\n",
    "        formatted_data_path = 'fifa_data2.csv'\n",
    "\n",
    "        # uncomment to save to csv\n",
    "        write_arr_to_csv(output_with_times, formatted_data_path)\n",
    "    if go_ahead == 'skip':\n",
    "        break\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-19T23:05:37.841918Z",
     "start_time": "2024-04-19T23:05:32.924930Z"
    }
   },
   "id": "5ed1179e1c536bfc",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-18T17:54:31.098929Z",
     "start_time": "2024-04-18T17:54:31.094247Z"
    }
   },
   "id": "8e1d2d2835ea55ba",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9a01c3ac2c1b024"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
